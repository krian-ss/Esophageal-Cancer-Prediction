{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827fecc-7b07-4c9f-8a6c-0031b8b85a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import itertools\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7  as PretrainedModel, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc74158-e2c4-47b0-9159-ce328e1a52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "folders = glob('D:/tester-esophagous' + '/*')\n",
    "print('New Paths: ', folders)\n",
    "\n",
    "IMAGE_FILES = glob('D:/tester-esophagous/endoscopy' + '/*/*.*')\n",
    "print('Images Count: ', len(IMAGE_FILES))\n",
    "\n",
    "SAMPLES = [\n",
    "    \"D:/tester-esophagous/endoscopy/noesophagous/0b792e26-e1dd-4fb7-a6b7-5d76f227a677.jpg\",\n",
    "    \"D:/tester-esophagous/endoscopy/esophagous/0c61343a-52a3-4f9b-85c3-732637968885.jpg\",    \n",
    "    \"D:/tester-esophagous/endoscopy/noesophagous/0c4091c0-2f80-4473-8362-041200f056ba.jpg\",\n",
    "    \"D:/tester-esophagous/endoscopy/esophagous/0f8d0452-78f0-4f1b-922c-ffdd56a57a4a.jpg\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, img_path in enumerate(SAMPLES):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    plt.subplot(1, len(SAMPLES), i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf982176-994e-4a1b-bc9e-b6c36a5806f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model preparation\n",
    "base_model = PretrainedModel(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "EsophagealCancer_Model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "EsophagealCancer_Model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd2451-60d0-472c-b4d1-54867c16fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:/tester-esophagous/endoscopy',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'D:/tester-esophagous/endoscopy',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882f23c-f072-4f07-83e7-300fded63e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = EsophagealCancer_Model.fit(\n",
    "    train_generator, \n",
    "    validation_data=validation_generator, \n",
    "    epochs=3, \n",
    "    verbose=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f7c72-9664-4d77-95e3-8c1b13647f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy', color='r')\n",
    "plt.plot(val_acc, label='Validation Accuracy', color='b')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.ylabel('Accuracy', fontsize=16, weight='bold')\n",
    "plt.title('Training & Validation Accuracy', fontsize=16, weight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss', color='r')\n",
    "plt.plot(val_loss, label='Validation Loss', color='b')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='upper right', fontsize=13)\n",
    "plt.ylabel('Cross Entropy', fontsize=16, weight='bold')\n",
    "plt.title('Training & Validation Loss', fontsize=15, weight='bold')\n",
    "plt.xlabel('Epoch', fontsize=15, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e937b87-5157-45e7-85ec-e84045874ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "EsophagealCancer_Model.save('D:/tester-esophagous/model/EsophagealCancerModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776a968-3edc-4046-9ef5-eb23d1b55712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows output with help of background code\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "#Code to predict the Esophageal Cancer based on the accuracy/confidence\n",
    "def predict_esophageal_cancer(image_path, model_path='D:/tester-esophagous/model/EsophagealCancerModel.keras'):\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "   \n",
    "    # Load and preprocess the image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "   \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "   \n",
    "    # Interpret the result\n",
    "    if prediction[0][0] > 0.5:\n",
    "        result = \"Esophageal cancer detected\"\n",
    "        probability = prediction[0][0]\n",
    "    else:\n",
    "        result = \"No esophageal cancer detected\"\n",
    "        probability = 1 - prediction[0][0]\n",
    "   \n",
    "    return result, probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b5c75-1dc3-44e1-9c08-40ebcd5dac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = 'D:/tester-esophagous/Esophagous-cancer-detection-testing-image/images.jpg'  # Replace with the path to your image\n",
    "result, probability = predict_esophageal_cancer(image_path)\n",
    "print(f\"Prediction: {result}\")\n",
    "print(f\"Confidence: {probability:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
